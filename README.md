<div align="center">
  <h3>
    <a href="#english">English</a>
    <span> | </span>
    <a href="#turkish">TÃ¼rkÃ§e</a>
  </h3>
</div>

---

<div id="english"></div>

# ğŸ‡¬ğŸ‡§ Credit Risk Scoring System (SQL & Python ETL)

This project is an end-to-end **Data Engineering (ETL)** and **Machine Learning** system designed for the banking sector.

The primary goal is to process a raw **SQL Server** database containing potential data quality issues using Python, clean/optimize it, and develop an AI model to predict loan defaults.

## ğŸš€ Project Scenario & Workflow

A "Data-First" approach was adopted for this project. The workflow consists of three main stages:

1.  **Database Simulation (SQL):** A dataset representing raw banking data (including potential outliers, missing values, or inconsistencies) is stored in SQL Server.
2.  **ETL Pipeline (Python):**
    * **Extract:** Python connects to SQL Server and retrieves the raw data.
    * **Transform:** Data is cleaned (handling errors, correcting typos), missing values are filled, and it is preprocessed for machine learning.
    * **Load:** The cleaned data is updated back into the database system.
3.  **Risk Modeling:** A **Logistic Regression** algorithm is trained on the clean data to predict the probability of a customer defaulting on a loan.

## ğŸ› ï¸ Tech Stack

* **Database:** Microsoft SQL Server (T-SQL)
* **Language:** Python 3.x
* **ETL & Data Processing:** `pandas`, `numpy`, `sqlalchemy`, `pyodbc`
* **Machine Learning:** `scikit-learn` (Logistic Regression, StandardScaler)

## ğŸ“‚ Project Files

* **`Credit-Risk-Score/Create-Database-Or-Tables-MSSQL/createDatabaseOrTable1.sql`**: SQL scripts used to create the table structure and populate raw data in SQL Server.
* **`Credit-Risk-Score/Python-ETL-Logistic-Regression/banksCreditWork.ipynb`**: The main Jupyter Notebook that connects to SQL, cleans the data (ETL), updates the database, and trains the AI model.
* **`Credit-Risk-Score/bank_loan_data_raw.csv`**: The raw dataset used for the project.
* **`Credit-Risk-Score/VariablesDetails.docx`**: Documentation describing the variables and data dictionary.

## ğŸ“Š Model Results

* **Algorithm:** Logistic Regression (with Balanced Class Weight)
* **Performance:** The model demonstrates the capability to transform raw SQL data into actionable insights, successfully identifying high-risk customers (Defaults).

---

<div id="turkish"></div>

# ğŸ‡¹ğŸ‡· Kredi Risk Skorlama Sistemi (SQL & Python ETL)

Bu proje, bankacÄ±lÄ±k verileri Ã¼zerinde **Veri MÃ¼hendisliÄŸi (ETL)** ve **Makine Ã–ÄŸrenmesi** sÃ¼reÃ§lerini uygulayan uÃ§tan uca bir risk tahminleme sistemidir.

Projenin temel amacÄ±; ham ve hatalÄ± verilerle dolu bir **SQL Server** veritabanÄ±nÄ± Python ile temizleyip optimize etmek ve mÃ¼ÅŸterilerin kredi batÄ±k durumunu (Loan Default) tahmin eden bir yapay zeka modeli geliÅŸtirmektir.

## ğŸš€ Proje Senaryosu ve Ä°ÅŸ AkÄ±ÅŸÄ±

Bu projede "Data-First" (Ã–nce Veri) yaklaÅŸÄ±mÄ± izlenmiÅŸtir. SÃ¼reÃ§ ÅŸu adÄ±mlardan oluÅŸur:

1.  **VeritabanÄ± SimÃ¼lasyonu (SQL):** Ä°Ã§erisinde bilinÃ§li hatalar (aykÄ±rÄ± deÄŸerler, eksik veriler, tutarsÄ±z metinler) barÄ±ndÄ±ran ham veri seti SQL Server Ã¼zerinde tutulmaktadÄ±r.
2.  **ETL Pipeline (Python):**
    * **Extract (Ã‡Ä±karma):** Python, SQL Server'a baÄŸlanÄ±r ve kirli veriyi Ã§eker.
    * **Transform (DÃ¶nÃ¼ÅŸtÃ¼rme):** Veriler temizlenir (hatalÄ± yaÅŸlar, yazÄ±m yanlÄ±ÅŸlarÄ± dÃ¼zeltilir), eksik veriler doldurulur ve makine Ã¶ÄŸrenmesine hazÄ±r hale getirilir.
    * **Load (YÃ¼kleme):** Temizlenen veri, veritabanÄ±na geri kaydedilerek gÃ¼ncellenir.
3.  **Risk Modellemesi:** Temiz veriler Ã¼zerinden **Lojistik Regresyon** algoritmasÄ± kullanÄ±larak kredi batÄ±k ihtimali tahmin edilir.

## ğŸ› ï¸ KullanÄ±lan Teknolojiler

* **VeritabanÄ±:** Microsoft SQL Server (T-SQL)
* **Programlama Dili:** Python 3.x
* **Veri Ä°ÅŸleme & ETL:** `pandas`, `numpy`, `sqlalchemy`, `pyodbc`
* **Makine Ã–ÄŸrenmesi:** `scikit-learn` (Logistic Regression, StandardScaler)

## ğŸ“‚ Proje DosyalarÄ±

* **`Credit-Risk-Score/Create-Database-Or-Tables-MSSQL/createDatabaseOrTable1.sql`**: Ham verileri ve tablo yapÄ±sÄ±nÄ± SQL Server'da oluÅŸturmak iÃ§in kullanÄ±lan scriptler.
* **`Credit-Risk-Score/Python-ETL-Logistic-Regression/banksCreditWork.ipynb`**: SQL'e baÄŸlanÄ±p veriyi temizleyen, veritabanÄ±nÄ± gÃ¼ncelleyen ve temiz veriyi kullanarak yapay zeka modelini eÄŸiten ana Python kodu (Notebook).
* **`Credit-Risk-Score/bank_loan_data_raw.csv`**: Projede kullanÄ±lan ham veri seti.
* **`Credit-Risk-Score/VariablesDetails.docx`**: DeÄŸiÅŸkenlerin ve sÃ¼tunlarÄ±n ne anlama geldiÄŸini aÃ§Ä±klayan dokÃ¼man.

## ğŸ“Š Model SonuÃ§larÄ±

* **Algoritma:** Logistic Regression (DengelenmiÅŸ SÄ±nÄ±f AÄŸÄ±rlÄ±ÄŸÄ± ile)
* **BaÅŸarÄ±:** Model, ham SQL verisini anlamlÄ± bir iÃ§gÃ¶rÃ¼ye dÃ¶nÃ¼ÅŸtÃ¼rerek riskli mÃ¼ÅŸterileri (Default) ayÄ±rt etme yeteneÄŸine sahiptir.
